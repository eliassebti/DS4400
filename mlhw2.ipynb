{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:50.900240Z",
     "start_time": "2026-02-16T03:33:50.882608Z"
    }
   },
   "source": [
    "# Data Clean\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "train_data = train_data.drop(columns = ['zipcode'])\n",
    "test_data = test_data.drop( columns = ['id','date','zipcode'])\n",
    "# ID date zipcode\n",
    "test_data.columns"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'lat',\n",
       "       'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:51.009244Z",
     "start_time": "2026-02-16T03:33:50.924017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#C2.1\n",
    "X = train_data.drop(columns = ['Unnamed: 0','price'])\n",
    "y = train_data['price']\n",
    "\n",
    "X_const_train = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_const_train).fit()\n",
    "print(\"Coefficients:\\n\", model.params)\n",
    "\n",
    "y_pred_train = model.predict(X_const_train)\n",
    "\n",
    "mse = mean_squared_error(y, y_pred_train)\n",
    "r2 = model.rsquared\n",
    "\n",
    "\n",
    "print(\"Training MSE:\", mse)\n",
    "print(\"Training R^2:\", r2)\n",
    "\n",
    "print(model.summary())\n"
   ],
   "id": "b0c2e71cf5977d1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      " const           -2.308890e+07\n",
      "bedrooms        -1.470428e+04\n",
      "bathrooms        2.568778e+04\n",
      "sqft_living      8.308361e+01\n",
      "sqft_lot         3.759298e-01\n",
      "floors           1.555558e+04\n",
      "waterfront       7.155352e+05\n",
      "view             6.302790e+04\n",
      "condition        1.881640e+04\n",
      "grade            7.953460e+04\n",
      "sqft_above       4.201109e+01\n",
      "sqft_basement    4.107431e+01\n",
      "yr_built        -2.400669e+03\n",
      "yr_renovated     4.368294e+01\n",
      "lat              5.535050e+05\n",
      "long            -7.424027e+03\n",
      "sqft_living15    6.801579e+01\n",
      "sqft_lot15      -5.155276e-01\n",
      "dtype: float64\n",
      "Training MSE: 31486167775.794846\n",
      "Training R^2: 0.7265334318706022\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.727\n",
      "Model:                            OLS   Adj. R-squared:                  0.722\n",
      "Method:                 Least Squares   F-statistic:                     163.2\n",
      "Date:                Sun, 15 Feb 2026   Prob (F-statistic):          2.71e-263\n",
      "Time:                        22:33:50   Log-Likelihood:                -13505.\n",
      "No. Observations:                1000   AIC:                         2.704e+04\n",
      "Df Residuals:                     983   BIC:                         2.713e+04\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const         -2.309e+07   6.73e+06     -3.429      0.001   -3.63e+07   -9.87e+06\n",
      "bedrooms       -1.47e+04   8429.534     -1.744      0.081   -3.12e+04    1837.670\n",
      "bathrooms      2.569e+04   1.36e+04      1.892      0.059    -950.131    5.23e+04\n",
      "sqft_living      83.0836      9.714      8.553      0.000      64.021     102.146\n",
      "sqft_lot          0.3759      0.357      1.052      0.293      -0.325       1.077\n",
      "floors         1.556e+04   1.55e+04      1.005      0.315   -1.48e+04    4.59e+04\n",
      "waterfront     7.155e+05   7.01e+04     10.201      0.000    5.78e+05    8.53e+05\n",
      "view           6.303e+04   9008.311      6.997      0.000    4.54e+04    8.07e+04\n",
      "condition      1.882e+04   9109.655      2.066      0.039     939.796    3.67e+04\n",
      "grade          7.953e+04   9079.972      8.759      0.000    6.17e+04    9.74e+04\n",
      "sqft_above       42.0111     10.172      4.130      0.000      22.049      61.973\n",
      "sqft_basement    41.0743     11.061      3.714      0.000      19.369      62.780\n",
      "yr_built      -2400.6693    310.728     -7.726      0.000   -3010.435   -1790.903\n",
      "yr_renovated     43.6829     15.621      2.796      0.005      13.029      74.337\n",
      "lat            5.535e+05   4.34e+04     12.742      0.000    4.68e+05    6.39e+05\n",
      "long          -7424.0271   5.08e+04     -0.146      0.884   -1.07e+05    9.22e+04\n",
      "sqft_living15    68.0158     16.496      4.123      0.000      35.645     100.387\n",
      "sqft_lot15       -0.5155      0.418     -1.233      0.218      -1.336       0.305\n",
      "==============================================================================\n",
      "Omnibus:                      462.551   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6365.579\n",
      "Skew:                           1.751   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.854   Cond. No.                     9.47e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.95e-22. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "C2.1 The MSE is 31486167775.794846 on training data, and the r squared value is 0.7265334318706022\n",
   "id": "5a2f9b4335898394"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:51.045452Z",
     "start_time": "2026-02-16T03:33:51.019575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C 2.2\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = test_data.drop(columns = ['Unnamed: 0','price'])\n",
    "y = test_data['price']\n",
    "X_const_test = sm.add_constant(X)\n",
    "\n",
    "y_pred_test = model.predict(X_const_test)\n",
    "\n",
    "mse = mean_squared_error(y, y_pred_test)\n",
    "r2 = r2_score(y, y_pred_test)\n",
    "\n",
    "print(\"Testing MSE:\", mse)\n",
    "print(\"Testing R^2:\", r2)\n",
    "\n",
    "print(model.summary())\n"
   ],
   "id": "5517bbed0c474f7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 57628154705.66643\n",
      "Testing R^2: 0.6543560876121193\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.727\n",
      "Model:                            OLS   Adj. R-squared:                  0.722\n",
      "Method:                 Least Squares   F-statistic:                     163.2\n",
      "Date:                Sun, 15 Feb 2026   Prob (F-statistic):          2.71e-263\n",
      "Time:                        22:33:51   Log-Likelihood:                -13505.\n",
      "No. Observations:                1000   AIC:                         2.704e+04\n",
      "Df Residuals:                     983   BIC:                         2.713e+04\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const         -2.309e+07   6.73e+06     -3.429      0.001   -3.63e+07   -9.87e+06\n",
      "bedrooms       -1.47e+04   8429.534     -1.744      0.081   -3.12e+04    1837.670\n",
      "bathrooms      2.569e+04   1.36e+04      1.892      0.059    -950.131    5.23e+04\n",
      "sqft_living      83.0836      9.714      8.553      0.000      64.021     102.146\n",
      "sqft_lot          0.3759      0.357      1.052      0.293      -0.325       1.077\n",
      "floors         1.556e+04   1.55e+04      1.005      0.315   -1.48e+04    4.59e+04\n",
      "waterfront     7.155e+05   7.01e+04     10.201      0.000    5.78e+05    8.53e+05\n",
      "view           6.303e+04   9008.311      6.997      0.000    4.54e+04    8.07e+04\n",
      "condition      1.882e+04   9109.655      2.066      0.039     939.796    3.67e+04\n",
      "grade          7.953e+04   9079.972      8.759      0.000    6.17e+04    9.74e+04\n",
      "sqft_above       42.0111     10.172      4.130      0.000      22.049      61.973\n",
      "sqft_basement    41.0743     11.061      3.714      0.000      19.369      62.780\n",
      "yr_built      -2400.6693    310.728     -7.726      0.000   -3010.435   -1790.903\n",
      "yr_renovated     43.6829     15.621      2.796      0.005      13.029      74.337\n",
      "lat            5.535e+05   4.34e+04     12.742      0.000    4.68e+05    6.39e+05\n",
      "long          -7424.0271   5.08e+04     -0.146      0.884   -1.07e+05    9.22e+04\n",
      "sqft_living15    68.0158     16.496      4.123      0.000      35.645     100.387\n",
      "sqft_lot15       -0.5155      0.418     -1.233      0.218      -1.336       0.305\n",
      "==============================================================================\n",
      "Omnibus:                      462.551   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6365.579\n",
      "Skew:                           1.751   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.854   Cond. No.                     9.47e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.95e-22. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "C 2.2\n",
    "The MSE is 57628154705.66643 and the R squared value is 0.6543560876121193\n",
    "\n",
    "C 2.3\n",
    "\n",
    "The r squared value didnt see to much change between train and test, showing that the model was decently fit. Test MSE/Train MSE was around 1.83 which is reason too believe the model is somewhat overfit. The features that contribute the most are the ones with lowest p-values, such as sqft_basement, sqft_above, waterfront, and view, all with p-values at or rounded too 0.00. The test MSE is 1.8 the train MSE showing that the model might be overfit on trian data, and needs further test data. The goal is for this number to be as close to one as possible.\n",
    "\n"
   ],
   "id": "211ed91cdfb0b8d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:51.064954Z",
     "start_time": "2026-02-16T03:33:51.050701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#C 3\n",
    "import numpy as np\n",
    "\n",
    "X_train = train_data.drop(columns = ['Unnamed: 0','price']).to_numpy()\n",
    "y_train = train_data['price'].to_numpy()\n",
    "\n",
    "X_test = test_data.drop(columns = ['Unnamed: 0','price']).to_numpy()\n",
    "y_test = test_data['price'].to_numpy()\n",
    "\n",
    "X_train = np.c_[np.ones(len(X_train)), X_train]\n",
    "X_test  = np.c_[np.ones(len(X_test)),  X_test]\n",
    "\n",
    "theta = np.linalg.pinv(X_train) @ y_train\n",
    "\n",
    "yhat_train = X_train @ theta\n",
    "yhat_test  = X_test @ theta\n",
    "\n",
    "test_MSE = mean_squared_error(y_test, yhat_test)\n",
    "test_R2 = r2_score(y_test, yhat_test)\n",
    "train_MSE = mean_squared_error(y_train, yhat_train)\n",
    "train_R2 = r2_score(y_train, yhat_train)\n",
    "\n",
    "\n",
    "print(\"Training MSE:\", train_MSE)\n",
    "print(\"Training R^2:\", train_R2)\n",
    "print(\"Testing MSE:\", test_MSE)\n",
    "print(\"Testing R^2:\", test_R2)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "bba2110f8cf87129",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 31486167775.794846\n",
      "Training R^2: 0.726533431870602\n",
      "Testing MSE: 57628154705.66643\n",
      "Testing R^2: 0.6543560876121193\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "C3, the models MSE and R2 Match for both testing and Training, demonstrating the behind the scenes calculations of linear regression models.",
   "id": "b6f01520bbe9aae9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:51.184719Z",
     "start_time": "2026-02-16T03:33:51.113545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#C4\n",
    "def make_poly_features(x, p):\n",
    "\n",
    "    x = np.asarray(x).reshape(-1, 1)\n",
    "\n",
    "    X_poly = np.ones((x.shape[0], p + 1))\n",
    "\n",
    "    for k in range(1, p + 1):\n",
    "        X_poly[:, k] = x[:, 0] ** k\n",
    "\n",
    "    return X_poly\n",
    "\n",
    "def fit_closed_form(X, y):\n",
    "    y = np.asarray(y).reshape(-1, 1)\n",
    "    return np.linalg.pinv(X) @ y\n",
    "\n",
    "def predict(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "x_train = train_data[\"sqft_living\"].to_numpy()\n",
    "y_train = train_data[\"price\"].to_numpy()\n",
    "\n",
    "x_test  = test_data[\"sqft_living\"].to_numpy()\n",
    "y_test  = test_data[\"price\"].to_numpy()\n",
    "\n",
    "degrees = [1, 2, 3, 5]\n",
    "rows = []\n",
    "\n",
    "for p in degrees:\n",
    "    Xtr = make_poly_features(x_train, p)\n",
    "    Xte = make_poly_features(x_test, p)\n",
    "\n",
    "    theta = fit_closed_form(Xtr, y_train)\n",
    "\n",
    "    yhat_tr = predict(Xtr, theta)\n",
    "    yhat_te = predict(Xte, theta)\n",
    "\n",
    "    mse_tr = mean_squared_error(y_train, yhat_tr)\n",
    "    r2_tr  = r2_score(y_train, yhat_tr)\n",
    "\n",
    "    mse_te = mean_squared_error(y_test, yhat_te)\n",
    "    r2_te  = r2_score(y_test, yhat_te)\n",
    "\n",
    "    rows.append([p, mse_tr, r2_tr, mse_te, r2_te])\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"Degree p\", \"MSE Train\", \"R² Train\", \"MSE Test\", \"R² Test\"]\n",
    ")\n",
    "\n",
    "results"
   ],
   "id": "5e79b78c25366201",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Degree p     MSE Train  R² Train      MSE Test     R² Test\n",
       "0         1  5.794753e+10  0.496709  8.857598e+10    0.468736\n",
       "1         2  5.482267e+10  0.523849  7.179168e+10    0.569406\n",
       "2         3  5.378519e+10  0.532860  9.983348e+10    0.401216\n",
       "3         5  5.411491e+10  0.529996  9.326506e+13 -558.388064"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Degree p</th>\n",
       "      <th>MSE Train</th>\n",
       "      <th>R² Train</th>\n",
       "      <th>MSE Test</th>\n",
       "      <th>R² Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.794753e+10</td>\n",
       "      <td>0.496709</td>\n",
       "      <td>8.857598e+10</td>\n",
       "      <td>0.468736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.482267e+10</td>\n",
       "      <td>0.523849</td>\n",
       "      <td>7.179168e+10</td>\n",
       "      <td>0.569406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.378519e+10</td>\n",
       "      <td>0.532860</td>\n",
       "      <td>9.983348e+10</td>\n",
       "      <td>0.401216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5.411491e+10</td>\n",
       "      <td>0.529996</td>\n",
       "      <td>9.326506e+13</td>\n",
       "      <td>-558.388064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "C4: As the degree P increases from 1 to 2 the test r2 increases and the mse decrease showcaseing a more accurate model. When degree goes past 3 the returns diminish, r2 drops around from 0.569 to 0.401(when degree of p is 3). When the degree level is 5, the r2 value falls below zero signaling the model prediction error is larger than the baseline error.",
   "id": "c60c512356138323"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:51.298262Z",
     "start_time": "2026-02-16T03:33:51.223599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C 5.1\n",
    "def add_intercept(X):\n",
    "    X = np.asarray(X)\n",
    "    return np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "def standardize_train_test(X_train_raw, X_test_raw):\n",
    "\n",
    "    X_train_raw = np.asarray(X_train_raw, dtype=float)\n",
    "    X_test_raw  = np.asarray(X_test_raw, dtype=float)\n",
    "\n",
    "    mu = X_train_raw.mean(axis=0)\n",
    "    sigma = X_train_raw.std(axis=0)\n",
    "    sigma[sigma == 0] = 1.0\n",
    "\n",
    "    X_train = (X_train_raw - mu) / sigma\n",
    "    X_test  = (X_test_raw - mu) / sigma\n",
    "    return X_train, X_test, mu, sigma\n",
    "\n",
    "def gradient_descent(X, y, alpha, iters):\n",
    "\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=float).reshape(-1, 1)\n",
    "    N, d = X.shape\n",
    "\n",
    "    theta = np.zeros((d, 1), dtype=float)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        grad = (2.0 / N) * (X.T @ (X @ theta - y))\n",
    "        theta = theta - alpha * grad\n",
    "\n",
    "\n",
    "        if not np.isfinite(theta).all():\n",
    "            break\n",
    "\n",
    "    return theta\n",
    "\n",
    "# C 5.2\n",
    "def eval_model(X, y, theta):\n",
    "    y = np.asarray(y, dtype=float).reshape(-1, 1)\n",
    "    yhat = np.asarray(X, dtype=float) @ np.asarray(theta, dtype=float)\n",
    "\n",
    "\n",
    "    if not np.isfinite(yhat).all():\n",
    "        return np.inf, -np.inf\n",
    "\n",
    "    mse = mean_squared_error(y, yhat)\n",
    "    r2 = r2_score(y, yhat)\n",
    "    return mse, r2\n",
    "\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if c not in [\"price\", \"Unnamed: 0\"]]\n",
    "\n",
    "X_train_raw = train_data[feature_cols].to_numpy()\n",
    "y_train = train_data[\"price\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "X_test_raw = test_data[feature_cols].to_numpy()\n",
    "y_test = test_data[\"price\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "\n",
    "X_train_scaled, X_test_scaled, mu, sigma = standardize_train_test(X_train_raw, X_test_raw)\n",
    "X_train = add_intercept(X_train_scaled)\n",
    "X_test  = add_intercept(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alphas = [0.01, 0.1, 0.5]\n",
    "iters_list = [10, 50, 100]\n",
    "\n",
    "rows = []\n",
    "for alpha in alphas:\n",
    "    for iters in iters_list:\n",
    "        theta = gradient_descent(X_train, y_train, alpha, iters)\n",
    "\n",
    "        mse_tr, r2_tr = eval_model(X_train, y_train, theta)\n",
    "        mse_te, r2_te = eval_model(X_test, y_test, theta)\n",
    "\n",
    "\n",
    "        rows.append([\n",
    "            alpha,\n",
    "            iters,\n",
    "            theta.flatten()[:5],\n",
    "            mse_tr, r2_tr,\n",
    "            mse_te, r2_te\n",
    "        ])\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"alpha\", \"iters\", \"theta(first 5)\", \"MSE Train\", \"R2 Train\", \"MSE Test\", \"R2 Test\"]\n",
    ")\n",
    "\n",
    "results\n"
   ],
   "id": "c6395ee72e5bbda7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   alpha  iters                                     theta(first 5)  \\\n",
       "0   0.01     10  [95198.02483770325, 11928.618743287172, 20283....   \n",
       "1   0.01     50  [330895.53038963006, 6005.279760915576, 23821....   \n",
       "2   0.01    100  [451397.6498338787, -3656.919333420636, 19241....   \n",
       "3   0.10     10  [464535.71669041866, -4645.6314527042505, 1873...   \n",
       "4   0.10     50  [520407.4063912902, -12457.193432165415, 17621...   \n",
       "5   0.10    100  [520414.83389399067, -12519.07659846653, 18424...   \n",
       "6   0.50     10  [520414.8342450353, -40545159636.12781, -60243...   \n",
       "7   0.50     50  [2.2615762850427088e+21, -3.770982340548436e+3...   \n",
       "8   0.50    100  [3.6686414568535576e+52, -6.124908928535069e+6...   \n",
       "\n",
       "       MSE Train       R2 Train       MSE Test        R2 Test  \n",
       "0   2.357278e+11  -1.047365e+00   2.805687e+11  -6.828036e-01  \n",
       "1   6.972050e+10   3.944571e-01   9.704954e+10   4.179133e-01  \n",
       "2   3.682035e+10   6.802045e-01   6.333304e+10   6.201392e-01  \n",
       "3   3.510510e+10   6.951019e-01   6.163043e+10   6.303511e-01  \n",
       "4   3.149726e+10   7.264371e-01   5.772248e+10   6.537904e-01  \n",
       "5   3.148643e+10   7.265311e-01   5.763896e+10   6.542913e-01  \n",
       "6   1.456064e+23  -1.264635e+12   1.626068e+23  -9.752880e+11  \n",
       "7   1.259542e+73  -1.093949e+62   1.406601e+73  -8.436553e+61  \n",
       "8  3.322792e+135 -2.885942e+124  3.710745e+135 -2.225642e+124  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>iters</th>\n",
       "      <th>theta(first 5)</th>\n",
       "      <th>MSE Train</th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>MSE Test</th>\n",
       "      <th>R2 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>[95198.02483770325, 11928.618743287172, 20283....</td>\n",
       "      <td>2.357278e+11</td>\n",
       "      <td>-1.047365e+00</td>\n",
       "      <td>2.805687e+11</td>\n",
       "      <td>-6.828036e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>[330895.53038963006, 6005.279760915576, 23821....</td>\n",
       "      <td>6.972050e+10</td>\n",
       "      <td>3.944571e-01</td>\n",
       "      <td>9.704954e+10</td>\n",
       "      <td>4.179133e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>[451397.6498338787, -3656.919333420636, 19241....</td>\n",
       "      <td>3.682035e+10</td>\n",
       "      <td>6.802045e-01</td>\n",
       "      <td>6.333304e+10</td>\n",
       "      <td>6.201392e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>[464535.71669041866, -4645.6314527042505, 1873...</td>\n",
       "      <td>3.510510e+10</td>\n",
       "      <td>6.951019e-01</td>\n",
       "      <td>6.163043e+10</td>\n",
       "      <td>6.303511e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>50</td>\n",
       "      <td>[520407.4063912902, -12457.193432165415, 17621...</td>\n",
       "      <td>3.149726e+10</td>\n",
       "      <td>7.264371e-01</td>\n",
       "      <td>5.772248e+10</td>\n",
       "      <td>6.537904e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>[520414.83389399067, -12519.07659846653, 18424...</td>\n",
       "      <td>3.148643e+10</td>\n",
       "      <td>7.265311e-01</td>\n",
       "      <td>5.763896e+10</td>\n",
       "      <td>6.542913e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>[520414.8342450353, -40545159636.12781, -60243...</td>\n",
       "      <td>1.456064e+23</td>\n",
       "      <td>-1.264635e+12</td>\n",
       "      <td>1.626068e+23</td>\n",
       "      <td>-9.752880e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>[2.2615762850427088e+21, -3.770982340548436e+3...</td>\n",
       "      <td>1.259542e+73</td>\n",
       "      <td>-1.093949e+62</td>\n",
       "      <td>1.406601e+73</td>\n",
       "      <td>-8.436553e+61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>[3.6686414568535576e+52, -6.124908928535069e+6...</td>\n",
       "      <td>3.322792e+135</td>\n",
       "      <td>-2.885942e+124</td>\n",
       "      <td>3.710745e+135</td>\n",
       "      <td>-2.225642e+124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "C 5.1: At step size 0.01 the performance improves as iter goes from 10 to 50 to 100, showing slow and increasing progression in r2 score from negative value after 10 iter, to 0.62 at 100 iter.\n",
    "\n",
    "At step size 0.10 after 10 iter the r2 value is 0.63, after 50 the r2 vlue is 0.65 and converges to near this value at step size 100 aswell.\n",
    "\n",
    "At step size 0.50, the r2 value never positive, signaling the model prediction error is larger than the baseline error. This is because the step size is too large, the model acuratly converge.\n",
    "\n",
    "At a high level, you dont want step size to be too small, because it takes many itnerations too find the min, and this uses more compute. You dont want step size to be large because then convergence cannot be found. In this instance step ize 0.1 was able to get to convergece the qucikest, only needing between 10-50 iter."
   ],
   "id": "1f61492fa6235a0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:51.309820Z",
     "start_time": "2026-02-16T03:33:51.306085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# C 6.2\n",
    "def ridge_gradient_descent(X, y, alpha, iters, lam, penalize_intercept=False):\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=float).reshape(-1, 1)\n",
    "    N, d = X.shape\n",
    "\n",
    "    theta = np.zeros((d, 1), dtype=float)\n",
    "\n",
    "    for _ in range(iters):\n",
    "\n",
    "        grad = (2.0 / N) * (X.T @ (X @ theta - y))\n",
    "\n",
    "\n",
    "        reg = 2.0 * lam * theta\n",
    "        if not penalize_intercept:\n",
    "            reg[0, 0] = 0.0\n",
    "\n",
    "        theta = theta - alpha * (grad + reg)\n",
    "\n",
    "\n",
    "        if not np.isfinite(theta).all():\n",
    "            break\n",
    "\n",
    "    return theta\n"
   ],
   "id": "ca313b1c30139810",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T03:33:51.384225Z",
     "start_time": "2026-02-16T03:33:51.354658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#C 6.3\n",
    "def closed_form_linear(X, y):\n",
    "    return np.linalg.pinv(X) @ y\n",
    "\n",
    "def closed_form_ridge(X, y, lam, penalize_intercept=False):\n",
    "    d = X.shape[1]\n",
    "    I = np.eye(d)\n",
    "    if not penalize_intercept:\n",
    "        I[0, 0] = 0.0\n",
    "    A = X.T @ X + lam * I\n",
    "    b = X.T @ y\n",
    "    return np.linalg.solve(A, b)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "N = 1000\n",
    "\n",
    "x = np.random.uniform(-2, 2, size=N)\n",
    "\n",
    "\n",
    "e = np.random.normal(0, np.sqrt(2), size=N)\n",
    "\n",
    "y = 1 + 2*x + e\n",
    "\n",
    "Xmat = np.c_[np.ones(N), x]\n",
    "yvec = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "\n",
    "theta_ols = closed_form_linear(Xmat, yvec)\n",
    "yhat_ols = (Xmat @ theta_ols).ravel()\n",
    "rows.append([\"OLS\", 0, float(theta_ols[1]), mean_squared_error(y, yhat_ols), r2_score(y, yhat_ols)])\n",
    "\n",
    "for lam in [1, 10, 100, 1000, 10000]:\n",
    "    theta_r = closed_form_ridge(Xmat, yvec, lam, penalize_intercept=False)\n",
    "    yhat = (Xmat @ theta_r).ravel()\n",
    "    rows.append([\"Ridge\", lam, float(theta_r[1]), mean_squared_error(y, yhat), r2_score(y, yhat)])\n",
    "\n",
    "results = pd.DataFrame(rows, columns=[\"Model\", \"lambda\", \"slope(theta1)\", \"MSE\", \"R2\"])\n",
    "results\n"
   ],
   "id": "3e59e3b20560ff3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/11696qnd2qv0jr8vrz4tm_t40000gn/T/ipykernel_86155/4090513944.py:34: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rows.append([\"OLS\", 0, float(theta_ols[1]), mean_squared_error(y, yhat_ols), r2_score(y, yhat_ols)])\n",
      "/var/folders/tj/11696qnd2qv0jr8vrz4tm_t40000gn/T/ipykernel_86155/4090513944.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rows.append([\"Ridge\", lam, float(theta_r[1]), mean_squared_error(y, yhat), r2_score(y, yhat)])\n",
      "/var/folders/tj/11696qnd2qv0jr8vrz4tm_t40000gn/T/ipykernel_86155/4090513944.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rows.append([\"Ridge\", lam, float(theta_r[1]), mean_squared_error(y, yhat), r2_score(y, yhat)])\n",
      "/var/folders/tj/11696qnd2qv0jr8vrz4tm_t40000gn/T/ipykernel_86155/4090513944.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rows.append([\"Ridge\", lam, float(theta_r[1]), mean_squared_error(y, yhat), r2_score(y, yhat)])\n",
      "/var/folders/tj/11696qnd2qv0jr8vrz4tm_t40000gn/T/ipykernel_86155/4090513944.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rows.append([\"Ridge\", lam, float(theta_r[1]), mean_squared_error(y, yhat), r2_score(y, yhat)])\n",
      "/var/folders/tj/11696qnd2qv0jr8vrz4tm_t40000gn/T/ipykernel_86155/4090513944.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rows.append([\"Ridge\", lam, float(theta_r[1]), mean_squared_error(y, yhat), r2_score(y, yhat)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Model  lambda  slope(theta1)       MSE        R2\n",
       "0    OLS       0       1.965692  1.865374  0.736759\n",
       "1  Ridge       1       1.964238  1.865377  0.736759\n",
       "2  Ridge      10       1.951251  1.865656  0.736720\n",
       "3  Ridge     100       1.830236  1.890166  0.733261\n",
       "4  Ridge    1000       1.129641  2.809812  0.603481\n",
       "5  Ridge   10000       0.233982  5.917267  0.164958"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>lambda</th>\n",
       "      <th>slope(theta1)</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0</td>\n",
       "      <td>1.965692</td>\n",
       "      <td>1.865374</td>\n",
       "      <td>0.736759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1</td>\n",
       "      <td>1.964238</td>\n",
       "      <td>1.865377</td>\n",
       "      <td>0.736759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>10</td>\n",
       "      <td>1.951251</td>\n",
       "      <td>1.865656</td>\n",
       "      <td>0.736720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>100</td>\n",
       "      <td>1.830236</td>\n",
       "      <td>1.890166</td>\n",
       "      <td>0.733261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.129641</td>\n",
       "      <td>2.809812</td>\n",
       "      <td>0.603481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.233982</td>\n",
       "      <td>5.917267</td>\n",
       "      <td>0.164958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "C6.3 As lambda got larger, the MSE increased, and the r2 value decreased",
   "id": "9bd480ddbc9e1f41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
